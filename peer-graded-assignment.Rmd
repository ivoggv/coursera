---
title: "Peer-graded Assignment: Prediction Assignment"
author: "Ivo Giulietti"
date: "27/12/2021"
output:
  html_document:
    self_contained: true
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,message = FALSE,warning = FALSE)
```

## Data Prep

First we download the data from the URLs provided. Also we load the initial packages we are going to use. 

```{r library and variables}

library(tidyverse)
library(caret)
library(lubridate)
library(rattle)
library(DataExplorer)
library(doParallel)

url.train='https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv'
url.test='https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv'

```

We load the data,run a quick EDA and realize a lot of missing values. More than 95% in 97 columns. These columns might not be useful for our models. So we decided to  

```{r data download}

download.file(url.train,'train.csv',mode = 'wb')
#First row was imported with index numbers. I remove it 
train=read_csv('train.csv',lazy=FALSE) %>% select(-1) 

#DataExplorer::create_report(train)

download.file(url.test,'test.csv')
#First row was imported with index numbers. I remove it 
test=read_csv('test.csv',lazy=FALSE)%>% select(-1) 

dim(train)
dim(test)

train=train %>% 
        mutate(across(.cols = contains('arm|belt|dumbbell|forearm'),.fns = ~as.numeric))

missing_values=apply(train,2,function(x){length(which(is.na(x)))})

num_col=length(which(missing_values>0.9))

percentage.missing=missing_values/nrow(train)


train=train%>% select(-names(missing_values)[missing_values>0.9]) %>% mutate(classe=as.factor(classe))

```

## Model

### Data Partition & Cluster

```{r data partition}

nucleos=detectCores()-1
cl <- makeCluster(nucleos)
registerDoParallel(cl)

set.seed(12486)
#Creo datasets de training y testing
inTrain = createDataPartition(y=train$classe,
                              p=0.8,list=FALSE)

training=train[inTrain,]
testing=train[-inTrain,]

```


### Decision Tree

First option is to see how a decision tree performs. We will perform a BoxCox preprocess to obtain better results. We also tried without preprocessing, center scale and pca analysis. Nevertheless BoxCox performed the best. 

```{r decision tree}

set.seed(45687)
fit.dt = train(classe ~ .,
              method = 'rpart',
              data = training,
              na.action=na.exclude,
              preProces=c('BoxCox'))

fit.dt
fancyRpartPlot(fit.dt$finalModel)

preddt=predict(fit.dt,newdata=testing)
confusionMatrix(preddt,testing$classe)


```

 This model doesnt seem to have a high accuracy. 
 
### Random Forest 

```{r random forest training, echo=FALSE,eval=FALSE}

set.seed(45687)
fit.rf = train(classe ~ .,
              method = 'rf',
              data = training,
              na.action=na.exclude,
              preProces=c('BoxCox'))

saveRDS(object = fit.rf,file = 'fit_rf.rsd')

```


```{r random forest testing}

fit.rf=readRDS('fit_rf.rsd')

tiempo=fit.rf$times$everything['elapsed']
tiempo.final=fit.rf$times$final['elapsed']



plot(fit.rf)

model.accuracy=postResample(pred = preddt, obs = testing$classe)['Accuracy']


preddt=predict(fit.rf,newdata=testing)

confusionMatrix(preddt,testing$classe)


col_index <- varImp(fit.rf)$importance %>% 
  mutate(names=row.names(.)) %>%
  arrange(-Overall)


```

Training this model without any further limitation on cross validation or the length of the tuning took `r tiempo/60` minutes to train. The final model took `r tiempo.final/60` minutes. If we have limited resources or time, we could train the model with less than 2 variables and we would get results of +98% as the graph shows. The optimum is about 40 Predictors. 

The accuracy of the model is formidable. Using the testing set we got an accuracy of  **99.94%** . Since we've got an almost perfect result on both training and testing we will not try other models. The training data set has been cross validated and everything appears to be in order. 

### Quiz 


Quiz resulted in 100% . 
```{r quiz}


preddt=predict(fit.rf,newdata=test)

preddt


```

